"""
Credibility Evaluation

This module provides functionality for evaluating the credibility of search results.
"""

import logging
import json
import hashlib
import time
from typing import List, Dict, Any
from urllib.parse import urlparse

from .models import SearchResult
from agents import client

# Configure logging
logger = logging.getLogger(__name__)

def evaluate_credibility(results: List[SearchResult], model: str) -> List[SearchResult]:
    """
    Evaluate the credibility of search results and assign credibility scores.
    Uses both URL-based heuristics and content-based LLM evaluation.
    
    Args:
        results: List of search results to evaluate
        model: LLM model to use for content evaluation
        
    Returns:
        List of search results with credibility scores assigned
    """
    logger.info("ğŸ§ æƒ…å ±ã®ä¿¡é ¼æ€§ã‚’è©•ä¾¡ä¸­...")
    
    try:
        # Simple baseline credibility evaluation based on source type
        for result in results:
            # Start with a baseline score based on source type
            if result.source_type == "web":
                result.credibility_score = 0.5  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸­ç«‹çš„ãª0.5ã«å¤‰æ›´
            elif result.source_type == "ai_search":
                result.credibility_score = 0.5
            elif result.source_type == "offline_synthetic":
                result.credibility_score = 0.4
            elif result.source_type == "synthetic":
                result.credibility_score = 0.3
            else:
                result.credibility_score = 0.3
            
            # Extract domain from URL for further analysis
            try:
                url_obj = urlparse(result.url)
                result.domain = url_obj.netloc
            except:
                result.domain = ""
            
            # Adjust scores based on domain characteristics
            if result.domain:
                # Academic and government sources tend to be more reliable
                if ".edu" in result.domain or ".gov" in result.domain:
                    result.credibility_score += 0.15
                # .org can be somewhat more credible, but not always
                elif ".org" in result.domain:
                    result.credibility_score += 0.1
                # Known reference sites
                elif any(ref in result.domain for ref in ["wikipedia.org", "britannica.com", "scholarpedia.org"]):
                    result.credibility_score += 0.1
                # News sources
                elif any(news in result.domain for news in ["bbc", "nytimes", "reuters", "apnews", "theguardian"]):
                    result.credibility_score += 0.1
                
                # Blogs and less formal sources may be less reliable
                if "blog." in result.domain or "blogs." in result.domain:
                    result.credibility_score -= 0.05
                
                # Social media tends to be less reliable for factual information
                if any(social in result.domain for social in ["facebook", "twitter", "reddit", "instagram", "tiktok"]):
                    result.credibility_score -= 0.1
                
                # Create a URL hash for tracking
                result.url_hash = hashlib.md5(result.url.encode()).hexdigest()
            
        # ----- Content-based credibility evaluation -----
        # Evaluate results that have content (snippet or content field)
        logger.info("ğŸ” ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ™ãƒ¼ã‚¹ã®ä¿¡é ¼æ€§åˆ†æã‚’å®Ÿè¡Œä¸­...")
        
        # Batch process results to reduce API calls
        batch_size = 3  # Number of results to evaluate at once
        batches = [results[i:i + batch_size] for i in range(0, len(results), batch_size)]
        
        # Counter for failed batches
        failed_batch_count = 0
        
        for batch_idx, batch in enumerate(batches):
            # Collect texts from each result in the batch
            batch_texts = []
            
            for result in batch:
                # Use content if available, otherwise use snippet
                content_text = result.content if result.content else result.snippet
                # Check minimum length
                if len(content_text) > 30:  # Only evaluate if there's enough content
                    batch_texts.append({
                        "url": result.url,
                        "title": result.title,
                        "content": content_text[:1000]  # Use first 1000 chars for long content
                    })
            
            # Only make API call if there's content to evaluate
            if batch_texts:
                try:
                    # Log start of processing for first batch
                    if batch_idx == 0:
                        logger.info(f"ä¿¡é ¼æ€§è©•ä¾¡ã‚’é–‹å§‹: å…¨ {len(batches)} ãƒãƒƒãƒã‚’å‡¦ç†ä¸­...")
                        
                    # Use OpenAI API to evaluate content credibility
                    response = client.chat.completions.create(
                        model=model,  # Use the provided model
                        messages=[
                            {"role": "system", "content": """
                            ã‚ãªãŸã¯æƒ…å ±ã®ä¿¡é ¼æ€§ã‚’è©•ä¾¡ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚æä¾›ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ã¤ã„ã¦ä»¥ä¸‹ã®åŸºæº–ã§è©•ä¾¡ã—ã¦ãã ã•ã„:
                            
                            1. äº‹å®Ÿç¢ºèªå¯èƒ½æ€§: æƒ…å ±ãŒæ¤œè¨¼å¯èƒ½ãªäº‹å®Ÿã«åŸºã¥ã„ã¦ã„ã‚‹ã‹
                            2. å®¢è¦³æ€§: åè¦‹ã‚„ä¸»è¦³çš„æ„è¦‹ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹
                            3. å°‚é–€æ€§: å°‚é–€çš„ãªçŸ¥è­˜ã‚„æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹
                            4. æœ€æ–°æ€§: æƒ…å ±ãŒæœ€æ–°ã‹ã©ã†ã‹ (æ—¥ä»˜ã‚„æ™‚é–“çš„æ–‡è„ˆã‹ã‚‰åˆ¤æ–­)
                            5. ä¸€è²«æ€§: å†…å®¹ã«çŸ›ç›¾ãŒãªã„ã‹
                            
                            å„URLã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«å¯¾ã—ã¦ã€0.0ã€œ1.0ã®ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
                            0.0ã¯ã€Œã¾ã£ãŸãä¿¡é ¼ã§ããªã„ã€ã€1.0ã¯ã€Œéå¸¸ã«ä¿¡é ¼ã§ãã‚‹ã€ã‚’æ„å‘³ã—ã¾ã™ã€‚
                            
                            å¿…ãšæ¬¡ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:
                            {
                              "results": [
                                {"url": "URL1", "credibility_score": 0.X, "reason": "ç°¡æ½”ãªç†ç”±"},
                                {"url": "URL2", "credibility_score": 0.Y, "reason": "ç°¡æ½”ãªç†ç”±"}
                              ]
                            }
                            """},
                            {"role": "user", "content": f"ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä¿¡é ¼æ€§ã‚’JSONå½¢å¼ã§è©•ä¾¡ã—ã¦ãã ã•ã„: {json.dumps(batch_texts, ensure_ascii=False)}"}
                        ],
                        response_format={"type": "json_object"},
                        temperature=0.2,
                        max_tokens=800
                    )
                    
                    # Parse response
                    try:
                        content = response.choices[0].message.content
                        assessment = json.loads(content)
                        
                        # Update scores for each result
                        for item in assessment.get("results", []):
                            url = item.get("url")
                            new_score = item.get("credibility_score")
                            reason = item.get("reason", "")
                            
                            # Find matching result and update
                            for result in batch:
                                if result.url == url and new_score is not None:
                                    # Combine domain-based score (40%) and content-based score (60%)
                                    domain_weight = 0.4
                                    content_weight = 0.6
                                    current_score = result.credibility_score
                                    
                                    # Calculate weighted average
                                    result.credibility_score = (current_score * domain_weight) + (new_score * content_weight)
                                    logger.debug(f"URL: {url} ã®ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ã‚’æ›´æ–°: {current_score:.2f} â†’ {result.credibility_score:.2f}, ç†ç”±: {reason}")
                        
                        # Batch processed successfully
                        failed_batch_count = 0  # Reset counter on success
                    
                    except json.JSONDecodeError:
                        failed_batch_count += 1
                        logger.debug("ä¿¡é ¼æ€§è©•ä¾¡ã®å¿œç­”ã‚’JSONã¨ã—ã¦è§£æã§ãã¾ã›ã‚“ã§ã—ãŸ")
                        if failed_batch_count == 1:  # Only show warning on first failure
                            logger.warning("âš ï¸ ä¸€éƒ¨ã®ä¿¡é ¼æ€§è©•ä¾¡ã«å•é¡ŒãŒã‚ã‚Šã¾ã—ãŸ")
                    except Exception as parse_err:
                        failed_batch_count += 1
                        logger.debug(f"ä¿¡é ¼æ€§è©•ä¾¡ã®å¿œç­”è§£æã‚¨ãƒ©ãƒ¼: {str(parse_err)}")
                        if failed_batch_count == 1:  # Only show warning on first failure
                            logger.warning("âš ï¸ ä¸€éƒ¨ã®ä¿¡é ¼æ€§è©•ä¾¡ã«å•é¡ŒãŒã‚ã‚Šã¾ã—ãŸ")
                
                except Exception as api_err:
                    # Log detailed error in debug log, show minimal info in console
                    logger.debug(f"ä¿¡é ¼æ€§è©•ä¾¡ã®APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(api_err)}")
                    failed_batch_count += 1
                    
                    # Only show warning on first failure
                    if failed_batch_count == 1:
                        logger.warning("âš ï¸ ä¸€éƒ¨ã®ä¿¡é ¼æ€§è©•ä¾¡ã«å•é¡ŒãŒã‚ã‚Šã¾ã—ãŸ")
                    
                    # If all batches have failed
                    if failed_batch_count >= len(batches):
                        logger.warning("âš ï¸ ä¿¡é ¼æ€§è©•ä¾¡ãŒå®Œå…¨ã«å¤±æ•—ã—ã¾ã—ãŸã€‚åŸºæœ¬ã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨ã—ã¾ã™")
                        # Apply basic scores (min 0.2, max 0.8)
                        for r in results:
                            if r.credibility_score < 0.2:
                                r.credibility_score = 0.3 + (hash(r.url) % 10) / 20  # Slight randomness based on URL hash
        
        # Completion message (after all batches)
        if len(batches) > 1:
            logger.info("âœ… ä¿¡é ¼æ€§è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸ")
        
        # Clip final scores to valid range (0.1-0.9)
        for result in results:
            result.credibility_score = max(0.1, min(0.9, result.credibility_score))
        
        logger.info(f"âœ… ä¿¡é ¼æ€§è©•ä¾¡å®Œäº†: URL + ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡")
        return results
        
    except Exception as e:
        logger.error(f"âŒ ä¿¡é ¼æ€§è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
        logger.info("âŒ ä¿¡é ¼æ€§è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™")
        
        # Return results with default scores if evaluation fails
        for result in results:
            if not hasattr(result, 'credibility_score') or result.credibility_score == 0:
                result.credibility_score = 0.5
        
        return results

def cluster_results(results: List[SearchResult]) -> List[SearchResult]:
    """
    Cluster results by domain to reduce redundancy.
    
    Args:
        results: List of search results to cluster
        
    Returns:
        Clustered list of search results
    """
    logger.info("ğŸ“Š æ¤œç´¢çµæœã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ä¸­...")
    domain_map = {}
    clustered_results = []
    
    for result in results:
        if result.domain not in domain_map:
            domain_map[result.domain] = []
        domain_map[result.domain].append(result)
    
    # Take the highest credibility result from each domain
    for domain, domain_results in domain_map.items():
        best_result = max(domain_results, key=lambda x: x.credibility_score)
        clustered_results.append(best_result)
    
    # Sort by credibility score
    clustered_results.sort(key=lambda x: x.credibility_score, reverse=True)
    logger.info(f"âœ… ã‚°ãƒ«ãƒ¼ãƒ—åŒ–å®Œäº†: {len(clustered_results)} ä»¶ã®çµæœ")
    return clustered_results 